{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71da2c91",
   "metadata": {},
   "source": [
    "# **Amazon Lookout for Equipment** - Getting started\n",
    "*Part 2 - Dataset creation*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13117a36",
   "metadata": {},
   "source": [
    "## Initialization\n",
    "---\n",
    "This repository is structured as follow:\n",
    "\n",
    "```sh\n",
    ". lookout-equipment-demo\n",
    "|\n",
    "├── data/\n",
    "|   ├── interim                          # Temporary intermediate data are stored here\n",
    "|   ├── processed                        # Finalized datasets are usually stored here\n",
    "|   |                                    # before they are sent to S3 to allow the\n",
    "|   |                                    # service to reach them\n",
    "|   └── raw                              # Immutable original data are stored here\n",
    "|\n",
    "├── getting_started/\n",
    "|   ├── 1_data_preparation.ipynb\n",
    "|   ├── 2_dataset_creation.ipynb         <<< THIS NOTEBOOK <<<\n",
    "|   ├── 3_model_training.ipynb\n",
    "|   ├── 4_model_evaluation.ipynb\n",
    "|   ├── 5_inference_scheduling.ipynb\n",
    "|   └── 6_cleanup.ipynb\n",
    "|\n",
    "└── utils/\n",
    "    └── lookout_equipment_utils.py\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535fd700",
   "metadata": {},
   "source": [
    "### Notebook configuration update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7ddd37",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --quiet --upgrade sagemaker tqdm lookoutequipment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a5446f",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4120fb44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import config\n",
    "import os\n",
    "import pandas as pd\n",
    "import pprint\n",
    "import sagemaker\n",
    "import sys\n",
    "import time\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "# SDK / toolbox for managing Lookout for Equipment API calls:\n",
    "import lookoutequipment as lookout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2adfe34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROCESSED_DATA = os.path.join('..', 'data', 'processed', 'getting-started')\n",
    "TRAIN_DATA     = os.path.join(PROCESSED_DATA, 'training-data')\n",
    "\n",
    "ROLE_ARN       = sagemaker.get_execution_role()\n",
    "REGION_NAME    = boto3.session.Session().region_name\n",
    "DATASET_NAME   = config.DATASET_NAME\n",
    "BUCKET         = config.BUCKET\n",
    "PREFIX         = config.PREFIX_TRAINING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5eb278",
   "metadata": {},
   "source": [
    "## Create a dataset\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69eb379",
   "metadata": {},
   "source": [
    "### Create data schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2264dd83",
   "metadata": {},
   "outputs": [],
   "source": [
    "lookout_dataset = lookout.LookoutEquipmentDataset(\n",
    "    dataset_name=DATASET_NAME,\n",
    "    component_root_dir=TRAIN_DATA,\n",
    "    access_role_arn=ROLE_ARN\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ec3d7e",
   "metadata": {},
   "source": [
    "If you wanted to use the console, the following string would be the one to use to configure the **dataset schema**:\n",
    "\n",
    "![Dataset creation with schema](assets/dataset-schema.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0870b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pp = pprint.PrettyPrinter(depth=5)\n",
    "pp.pprint(eval(lookout_dataset.dataset_schema))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a70f3451",
   "metadata": {},
   "source": [
    "The following method encapsulate the [**CreateDataset**](https://docs.aws.amazon.com/lookout-for-equipment/latest/ug/API_CreateDataset.html) API:\n",
    "\n",
    "```python\n",
    "lookout_client.create_dataset(\n",
    "    DatasetName=self.dataset_name,\n",
    "    DatasetSchema={\n",
    "        'InlineDataSchema': \"schema\"\n",
    "    }\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50cebae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "lookout_dataset.create()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9fe4ae0",
   "metadata": {},
   "source": [
    "The dataset is now created, but it is empty and ready to receive some timeseries data that we will ingest from the S3 location prepared in the previous notebook:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284aad7e",
   "metadata": {},
   "source": [
    "![Dataset created](assets/dataset-created.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9ce63e",
   "metadata": {},
   "source": [
    "## Ingest data into a dataset\n",
    "---\n",
    "Let's double check the values of all the parameters that will be used to ingest some data into an existing Lookout for Equipment dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b119a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROLE_ARN, BUCKET, PREFIX, DATASET_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42eaeb97",
   "metadata": {},
   "source": [
    "Launch the ingestion job in the Lookout for Equipment dataset: the following method encapsulates the [**StartDataIngestionJob**](https://docs.aws.amazon.com/lookout-for-equipment/latest/ug/API_StartDataIngestionJob.html) API:\n",
    "\n",
    "```python\n",
    "lookout_client.start_data_ingestion_job(\n",
    "    DatasetName=DATASET_NAME,\n",
    "    RoleArn=ROLE_ARN, \n",
    "    IngestionInputConfiguration={ \n",
    "        'S3InputConfiguration': { \n",
    "            'Bucket': BUCKET,\n",
    "            'Prefix': PREFIX\n",
    "        }\n",
    "    }\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ba52a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = lookout_dataset.ingest_data(BUCKET, PREFIX)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e06157",
   "metadata": {},
   "source": [
    "The ingestion is launched. With this amount of data (around 50 MB), it should take between less than 5 minutes:\n",
    "\n",
    "![dataset_schema](assets/dataset-ingestion-in-progress.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803b163f",
   "metadata": {},
   "source": [
    "We use the following cell to monitor the ingestion process by calling the following method, which encapsulates the [**DescribeDataIngestionJob**](https://docs.aws.amazon.com/lookout-for-equipment/latest/ug/API_DescribeDataIngestionJob.html) API and runs it every 60 seconds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f9f116",
   "metadata": {},
   "outputs": [],
   "source": [
    "lookout_dataset.poll_data_ingestion(sleep_time=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af37b31",
   "metadata": {},
   "source": [
    "In case any issue arise, you can inspect the API response available as a JSON document:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ce987b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lookout_dataset.ingestion_job_response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bfa9765",
   "metadata": {},
   "source": [
    "The ingestion should now be complete as can be seen in the console:\n",
    "\n",
    "![Ingestion done](assets/dataset-ingestion-done.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd334563",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c9d4e0",
   "metadata": {},
   "source": [
    "In this notebook, we created a **Lookout for Equipment dataset** and ingested the S3 data previously uploaded into this dataset. **Move now to the next notebook to train a model based on these data.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
