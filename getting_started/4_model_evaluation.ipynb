{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Amazon Lookout for Equipment** - Getting started\n",
    "*Part 4 - Model evaluation*\n",
    "\n",
    "## Initialization\n",
    "---\n",
    "This repository is structured as follow:\n",
    "\n",
    "```sh\n",
    ". lookout-equipment-demo\n",
    "|\n",
    "├── data/\n",
    "|   ├── interim                          # Temporary intermediate data\n",
    "|   ├── processed                        # Finalized datasets\n",
    "|   └── raw                              # Immutable original data\n",
    "|\n",
    "├── getting_started/\n",
    "|   ├── 1_data_preparation.ipynb\n",
    "|   ├── 2_dataset_creation.ipynb\n",
    "|   ├── 3_model_training.ipynb\n",
    "|   ├── 4_model_evaluation.ipynb               <<< THIS NOTEBOOK <<<\n",
    "|   ├── 5_inference_scheduling.ipynb\n",
    "|   ├── 6_visualization_with_quicksight.ipynb\n",
    "|   └── 7_cleanup.ipynb\n",
    "|\n",
    "└── utils/\n",
    "    └── lookout_equipment_utils.py\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook configuration update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --quiet --upgrade tqdm lookoutequipment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import config\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "# SDK / toolbox for managing Lookout for Equipment API calls:\n",
    "import lookoutequipment as lookout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AWS Look & Feel definition for Matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import font_manager\n",
    "\n",
    "# Load style sheet:\n",
    "plt.style.use('../utils/aws_matplotlib_template.py')\n",
    "\n",
    "# Get colors from custom AWS palette:\n",
    "prop_cycle = plt.rcParams['axes.prop_cycle']\n",
    "colors = prop_cycle.by_key()['color']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TMP_DATA       = os.path.join('..', 'data', 'interim', 'getting-started')\n",
    "PROCESSED_DATA = os.path.join('..', 'data', 'processed', 'getting-started')\n",
    "LABEL_DATA     = os.path.join(PROCESSED_DATA, 'label-data')\n",
    "TRAIN_DATA     = os.path.join(PROCESSED_DATA, 'training-data', 'centrifugal-pump')\n",
    "REGION_NAME    = boto3.session.Session().region_name\n",
    "MODEL_NAME     = config.MODEL_NAME\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuring time ranges:\n",
    "training_start   = pd.to_datetime('2019-01-01 00:00:00')\n",
    "training_end     = pd.to_datetime('2019-07-31 00:00:00')\n",
    "evaluation_start = pd.to_datetime('2019-08-01 00:00:00')\n",
    "evaluation_end   = pd.to_datetime('2019-10-27 00:00:00')\n",
    "\n",
    "print(f'  Training period | from {training_start} to {training_end}')\n",
    "print(f'Evaluation period | from {evaluation_start} to {evaluation_end}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading original datasets for visualization purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's load all our original signals (they will be useful later on):\n",
    "all_tags_fname = os.path.join(TRAIN_DATA, 'sensors.csv')\n",
    "all_tags_df = pd.read_csv(all_tags_fname)\n",
    "all_tags_df['Timestamp'] = pd.to_datetime(all_tags_df['Timestamp'])\n",
    "all_tags_df = all_tags_df.set_index('Timestamp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model evaluation\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [**DescribeModel**](https://docs.aws.amazon.com/lookout-for-equipment/latest/ug/API_DescribeModel.html) API can be used to extract, among other things, the metrics associated to the trained model. Here are the different fields available when calling this API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lookout_client = boto3.client('lookoutequipment')\n",
    "describe_model_response = lookout_client.describe_model(ModelName=MODEL_NAME)\n",
    "list(describe_model_response.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `ModelMetrics` field above is a dictionnary that follows this format:\n",
    "\n",
    "```json\n",
    "{\n",
    "    'labeled_ranges': [\n",
    "        {'start': '2019-08-08T00:00:00.000000', 'end': '2019-08-09T00:00:00.000000'},\n",
    "        {'start': '2019-08-18T00:00:00.000000', 'end': '2019-08-19T00:00:00.000000'},\n",
    "        {'start': '2019-08-28T00:00:00.000000', 'end': '2019-08-29T00:00:00.000000'},\n",
    "        {'start': '2019-09-07T00:00:00.000000', 'end': '2019-09-08T00:00:00.000000'},\n",
    "        {'start': '2019-09-17T00:00:00.000000', 'end': '2019-09-18T00:00:00.000000'},\n",
    "        {'start': '2019-09-27T00:00:00.000000', 'end': '2019-09-28T00:00:00.000000'},\n",
    "        {'start': '2019-10-07T00:00:00.000000', 'end': '2019-10-08T00:00:00.000000'},\n",
    "        {'start': '2019-10-17T00:00:00.000000', 'end': '2019-10-18T00:00:00.000000'}\n",
    "    ],\n",
    "    'labeled_event_metrics': {\n",
    "        'num_labeled': 8,\n",
    "        'num_identified': 8,\n",
    "        'total_warning_time_in_seconds': 668040.0\n",
    "    },\n",
    "    'predicted_ranges': [\n",
    "        {\n",
    "            'start': '2019-08-08T00:42:00.000000',\n",
    "            'end': '2019-08-08T01:48:00.000000',\n",
    "            'diagnostics': [\n",
    "                {'name': 'centrifugal-pump\\\\Sensor0', 'value': 0.05218326564181105},\n",
    "                {'name': 'centrifugal-pump\\\\Sensor1', 'value': 0.023636079094576},\n",
    "                {'name': 'centrifugal-pump\\\\Sensor2', 'value': 0.03825258734479793},\n",
    "                {'name': 'centrifugal-pump\\\\Sensor3', 'value': 0.023349531399873558},\n",
    "                \n",
    "                ...\n",
    "                \n",
    "                {'name': 'centrifugal-pump\\\\Sensor20', 'value': 0.04989340342761552},\n",
    "                {'name': 'centrifugal-pump\\\\Sensor21', 'value': 0.033976174168938014},\n",
    "                {'name': 'centrifugal-pump\\\\Sensor22', 'value': 0.046622167459421035},\n",
    "                {'name': 'centrifugal-pump\\\\Sensor23', 'value': 0.044698573526762944}\n",
    "            ]\n",
    "        },\n",
    "        \n",
    "        ...\n",
    "        \n",
    "    ],\n",
    "    'unknown_event_metrics': {\n",
    "        'num_identified': 8,\n",
    "        'total_duration_in_seconds': 4200.0\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "The `labeled_ranges` contains the label provided as an input while the `predicted_ranges` contains all the predicted ranges where Lookout for Equipment detected an anomaly. Each predicted range contains a `diagnostics` field with a percentage associated to each sensor available in the dataset. During the training, Lookout for Equipment learns the relationship between the sensors that denotes a normal behavior. When this normal relationship is broken, the service considers that it detected an an anomalous event. It then proceeds with calculating which sensors are indicating that the asset is no longer operating normally. You can read this diagnostic as a feature importance output of the model: the percentage associated to a given sensor corresponds to the magnitude of impact (*importance*) this sensor has with regards to a given anomaly.\n",
    "\n",
    "Let's use the following utility function get these results into two dataframes (labeled and predicted):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LookoutDiagnostics = lookout.LookoutEquipmentAnalysis(model_name=MODEL_NAME, tags_df=all_tags_df)\n",
    "LookoutDiagnostics.set_time_periods(evaluation_start, evaluation_end, training_start, training_end)\n",
    "predicted_ranges = LookoutDiagnostics.get_predictions()\n",
    "labels_fname = os.path.join(LABEL_DATA, 'labels.csv')\n",
    "labeled_range = LookoutDiagnostics.get_labels(labels_fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** the labeled range from the model Describe API, only provides any labelled data falling within the evaluation range. We use the original label data to get all of them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now display one of the original signal and map both the labeled and the predicted ranges on the same plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_colors = {\n",
    "    'labels': colors[9],\n",
    "    'predictions': colors[5]\n",
    "}\n",
    "    \n",
    "TSViz = lookout.plot.TimeSeriesVisualization(\n",
    "    timeseries_df=all_tags_df,\n",
    "    data_format='tabular'\n",
    ")\n",
    "TSViz.add_signal(['Sensor0'])\n",
    "TSViz.add_labels(labeled_range)\n",
    "TSViz.add_predictions([predicted_ranges])\n",
    "TSViz.add_train_test_split(evaluation_start)\n",
    "TSViz.legend_format = {\n",
    "    'loc': 'upper right',\n",
    "    'framealpha': 0.4,\n",
    "    'ncol': 2\n",
    "}\n",
    "fig, axis = TSViz.plot(fig_width=24, colors=custom_colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unpacking event details\n",
    "---\n",
    "### Single event overview\n",
    "Each detected event have some detailed diagnostics stored in JSON format. Let's unpack the event details for the first large event and plot a similar bar chart than what the console provides:\n",
    "\n",
    "![Event details](assets/model-diagnostics.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's get the details for one of the event:\n",
    "first_event_details = predicted_ranges.loc[1, 'diagnostics']\n",
    "first_event_details = pd.DataFrame(first_event_details).sort_values(by='value', ascending=False).reset_index(drop=True)\n",
    "first_event_details = first_event_details.sort_values(by='value')\n",
    "\n",
    "fig, ax = lookout.plot.plot_event_barh(first_event_details.iloc[0:, 0:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might be curious about why Amazon Lookout for Equipment detected an anomalous event. Sometime, looking at a few of the time series is enough. But sometime, you need to dig deeper.\n",
    "\n",
    "The following function, aggregate the signal importance of every signals over the evaluation period and sum these contributions over time for each signal. Then, it takes the top 8 signals and plot two distributions: one with the values each signal takes during the normal periods (present in the evaluation range) and a second one with the values taken during all the anomalous events detected in the evaluation range. This will help you visualize any significant shift of values for the top contributing signals.\n",
    "\n",
    "You can also restrict these histograms over a specific range of time by setting the start and end arguments of the following function with datetime values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_start = pd.to_datetime('2019-08-17 00:00:00')\n",
    "event_end = pd.to_datetime('2019-08-18 23:59:00')\n",
    "\n",
    "fig = TSViz.plot_histograms(freq='5min', start=event_start, end=event_end, top_n=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On these plots, you can see that the distributions of the sensor values when an event is detected are slightly wider than during the normal operation times."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grouping sensors by component\n",
    "The above bar chart is already a great help to pinpoint what might be going wrong with your asset. Let's load the initial tags description file we prepared in the first notebook and match the sensors with our initial components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_description_fname = os.path.join(TMP_DATA, 'tags_description.csv')\n",
    "tags_description_df = pd.read_csv(tags_description_fname)\n",
    "first_event_details[['asset', 'sensor']] = first_event_details['name'].str.split('\\\\', expand=True)\n",
    "component_diagnostics = pd.merge(first_event_details, tags_description_df, how='inner', left_on='sensor', right_on='Tag')[['name', 'value', 'Component']]\n",
    "component_diagnostics.sort_values(by='value', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we group the contribution of all sensors by component we end up seeing that the volute component has a 30% contribution to this particular event, while the other components are ranging from 16 to 19%: **time to give the volute a visit?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_diagnostics = component_diagnostics.groupby(by='Component').sum().sort_values(by='value')\n",
    "event_diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can then plot a horizontal bar chart:\n",
    "y_pos = np.arange(event_diagnostics.shape[0])\n",
    "values = list(event_diagnostics['value'])\n",
    "\n",
    "fig = plt.figure(figsize=(12,5))\n",
    "ax = plt.subplot(1,1,1)\n",
    "ax.barh(y_pos, event_diagnostics['value'], align='center')\n",
    "ax.set_yticks(y_pos)\n",
    "ax.set_yticklabels(list(event_diagnostics.index))\n",
    "ax.xaxis.set_major_formatter(mtick.PercentFormatter(1.0))\n",
    "\n",
    "# Add the values in each bar:\n",
    "for i, v in enumerate(values):\n",
    "    ax.text(0.005, i, f'{v*100:.2f}%', color='#FFFFFF', fontweight='bold', verticalalignment='center')\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we use the model created in part 3 of this notebook series and performed a few visualization and diagnostics on the results obtained. You can now move forward to the next step to the **inference scheduling notebook** where we will start the model, feed it some new data and catch the results."
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:eu-west-1:470317259841:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
