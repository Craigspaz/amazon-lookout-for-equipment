{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Amazon Lookout for Equipment** - Getting started\n",
    "*Part 7 - Cleanup*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization\n",
    "---\n",
    "This repository is structured as follow:\n",
    "\n",
    "```sh\n",
    ". lookout-equipment-demo\n",
    "|\n",
    "├── data/\n",
    "|   ├── interim                          # Temporary intermediate data\n",
    "|   ├── processed                        # Finalized datasets\n",
    "|   └── raw                              # Immutable original data\n",
    "|\n",
    "├── getting_started/\n",
    "|   ├── 1_data_preparation.ipynb\n",
    "|   ├── 2_dataset_creation.ipynb\n",
    "|   ├── 3_model_training.ipynb\n",
    "|   ├── 4_model_evaluation.ipynb\n",
    "|   ├── 5_inference_scheduling.ipynb\n",
    "|   ├── 6_visualization_with_quicksight.ipynb\n",
    "|   └── 7_cleanup.ipynb                        <<< THIS NOTEBOOK <<<\n",
    "|\n",
    "└── utils/\n",
    "    └── lookout_equipment_utils.py\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook configuration update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --quiet --upgrade sagemaker tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import config\n",
    "import datetime\n",
    "import sagemaker\n",
    "import sys\n",
    "import time\n",
    "\n",
    "# Helper functions for managing Lookout for Equipment API calls:\n",
    "sys.path.append('../utils')\n",
    "import lookout_equipment_utils as lookout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROLE_ARN                 = sagemaker.get_execution_role()\n",
    "REGION_NAME              = boto3.session.Session().region_name\n",
    "BUCKET                   = config.BUCKET\n",
    "PREFIX_TRAINING          = config.PREFIX_TRAINING\n",
    "PREFIX_LABEL             = config.PREFIX_LABEL\n",
    "PREFIX_INFERENCE         = config.PREFIX_INFERENCE\n",
    "DATASET_NAME             = config.DATASET_NAME\n",
    "MODEL_NAME               = config.MODEL_NAME\n",
    "INFERENCE_SCHEDULER_NAME = config.INFERENCE_SCHEDULER_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lookout_client = lookout.get_client(region_name=REGION_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deleting resources\n",
    "---\n",
    "### Deleting inference scheduler\n",
    "Using the [**DeleteInferenceScheduler**](https://docs.aws.amazon.com/lookout-for-equipment/latest/ug/API_DeleteInferenceScheduler.html) API to delete existing scheduler:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stopping the scheduler in case it's running:\n",
    "try:\n",
    "    print('Stopping the scheduler...')\n",
    "    scheduler = lookout.LookoutEquipmentScheduler(\n",
    "        scheduler_name=INFERENCE_SCHEDULER_NAME,\n",
    "        model_name=MODEL_NAME,\n",
    "        region_name=REGION_NAME\n",
    "    )\n",
    "    scheduler.stop()\n",
    "    scheduler.delete()\n",
    "    \n",
    "except Exception as e:\n",
    "    error_code = e.response['Error']['Code']\n",
    "    if (error_code == 'ResourceNotFoundException'):\n",
    "        print('  > Scheduler not found, nothing to do')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deleting the trained models\n",
    "Using the [**DeleteModel**](https://docs.aws.amazon.com/lookout-for-equipment/latest/ug/API_DeleteModel.html) API to remove the model trained in this tutorial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in lookout.list_models_for_datasets(model_name_prefix=MODEL_NAME):\n",
    "    print(f'Deleting model {model}...')\n",
    "    \n",
    "    try:\n",
    "        lookout_client.delete_model(ModelName=MODEL_NAME)\n",
    "        print(f'Model \"{MODEL_NAME}\" is deleted successfully.')\n",
    "\n",
    "    except Exception as e:\n",
    "        error_code = e.response['Error']['Code']\n",
    "        # If the dataset is used by existing models and we asked a\n",
    "        # forced delete, we also delete the associated models before\n",
    "        # trying again the dataset deletion:\n",
    "        if (error_code == 'ConflictException'):\n",
    "            print(('Model is currently being used (a training might be in '\n",
    "                   'progress. Wait for the process to be completed and '\n",
    "                   'retry.'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deleting the dataset\n",
    "Using the [**DeleteDataset**](https://docs.aws.amazon.com/lookout-for-equipment/latest/ug/API_DeleteDataset.html) API to remove the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try to delete this dataset:\n",
    "try:\n",
    "    lookout_client.delete_dataset(DatasetName=DATASET_NAME)\n",
    "    print(f'Dataset \"{DATASET_NAME}\" is deleted successfully.')\n",
    "\n",
    "except Exception as e:\n",
    "    error_code = e.response['Error']['Code']\n",
    "    if (error_code == 'ConflictException'):\n",
    "        print(('Dataset is used by at least a model, delete the '\n",
    "               'associated model(s) before deleting this dataset.'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning the S3 bucket\n",
    "Uncomment and run the following cell to clean the S3 bucket from the prefixes used throughout this tutorial for training data, label data and inference data. You can stop here if you would like to keep the data generated for further experimentation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !aws s3 rm s3://$BUCKET/$PREFIX_INFERENCE --recursive\n",
    "# !aws s3 rm s3://$BUCKET/$PREFIX_TRAINING --recursive\n",
    "# !aws s3 rm s3://$BUCKET/$PREFIX_LABEL --recursive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use this notebook to cleanup all the ressources created while running this series of tutorials."
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:eu-west-1:470317259841:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
