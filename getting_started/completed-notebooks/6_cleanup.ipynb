{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fixed-determination",
   "metadata": {},
   "source": [
    "# **Amazon Lookout for Equipment** - Getting started\n",
    "*Part 6 - Cleanup*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "removed-section",
   "metadata": {},
   "source": [
    "## Initialization\n",
    "---\n",
    "This repository is structured as follow:\n",
    "\n",
    "```sh\n",
    ". lookout-equipment-demo\n",
    "|\n",
    "├── data/\n",
    "|   ├── interim                          # Temporary intermediate data are stored here\n",
    "|   ├── processed                        # Finalized datasets are usually stored here\n",
    "|   |                                    # before they are sent to S3 to allow the\n",
    "|   |                                    # service to reach them\n",
    "|   └── raw                              # Immutable original data are stored here\n",
    "|\n",
    "├── getting_started/\n",
    "|   ├── 1_data_preparation.ipynb\n",
    "|   ├── 2_dataset_creation.ipynb\n",
    "|   ├── 3_model_training.ipynb\n",
    "|   ├── 4_model_evaluation.ipynb\n",
    "|   ├── 5_inference_scheduling.ipynb\n",
    "|   └── 6_cleanup.ipynb                  <<< THIS NOTEBOOK <<<\n",
    "|\n",
    "└── utils/\n",
    "    └── lookout_equipment_utils.py\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "breathing-stream",
   "metadata": {},
   "source": [
    "### Notebook configuration update\n",
    "Amazon Lookout for Equipment being a very recent service, we need to make sure that we have access to the latest version of the AWS Python packages. If you see a `pip` dependency error, check that the `boto3` version is ok before moving forward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "owned-regard",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "boto3 version: 1.17.50 (should be >= 1.17.48 to include Lookout for Equipment API)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<script>Jupyter.notebook.kernel.restart()</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install --quiet --upgrade boto3 sagemaker tqdm\n",
    "\n",
    "import boto3\n",
    "print(f'boto3 version: {boto3.__version__} (should be >= 1.17.48 to include Lookout for Equipment API)')\n",
    "\n",
    "# Restart the current notebook to ensure we take into account the previous updates:\n",
    "from IPython.core.display import HTML\n",
    "HTML(\"<script>Jupyter.notebook.kernel.restart()</script>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amber-plain",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "interesting-incident",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import config\n",
    "import datetime\n",
    "import sagemaker\n",
    "import sys\n",
    "import time\n",
    "\n",
    "# Helper functions for managing Lookout for Equipment API calls:\n",
    "sys.path.append('../utils')\n",
    "import lookout_equipment_utils as lookout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "difficult-mobile",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROLE_ARN                 = sagemaker.get_execution_role()\n",
    "REGION_NAME              = boto3.session.Session().region_name\n",
    "BUCKET                   = config.BUCKET\n",
    "PREFIX_TRAINING          = config.PREFIX_TRAINING\n",
    "PREFIX_LABEL             = config.PREFIX_LABEL\n",
    "PREFIX_INFERENCE         = config.PREFIX_INFERENCE\n",
    "DATASET_NAME             = config.DATASET_NAME\n",
    "MODEL_NAME               = config.MODEL_NAME\n",
    "INFERENCE_SCHEDULER_NAME = config.INFERENCE_SCHEDULER_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "supposed-airfare",
   "metadata": {},
   "outputs": [],
   "source": [
    "lookout_client = lookout.get_client(region_name=REGION_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "traditional-giant",
   "metadata": {},
   "source": [
    "## Deleting resources\n",
    "---\n",
    "### Deleting inference scheduler\n",
    "Using the [**DeleteInferenceScheduler**](https://docs.aws.amazon.com/lookout-for-equipment/latest/ug/API_DeleteInferenceScheduler.html) API to delete existing scheduler:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "communist-government",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping the scheduler...\n",
      "  > Scheduler not found, nothing to do\n"
     ]
    }
   ],
   "source": [
    "# Stopping the scheduler in case it's running:\n",
    "try:\n",
    "    print('Stopping the scheduler...')\n",
    "    scheduler = lookout.LookoutEquipmentScheduler(\n",
    "        scheduler_name=INFERENCE_SCHEDULER_NAME,\n",
    "        model_name=MODEL_NAME,\n",
    "        region_name=REGION_NAME\n",
    "    )\n",
    "    scheduler.stop()\n",
    "    scheduler.delete()\n",
    "    \n",
    "except Exception as e:\n",
    "    error_code = e.response['Error']['Code']\n",
    "    if (error_code == 'ResourceNotFoundException'):\n",
    "        print('  > Scheduler not found, nothing to do')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hazardous-speed",
   "metadata": {},
   "source": [
    "### Deleting the trained models\n",
    "Using the [**DeleteModel**](https://docs.aws.amazon.com/lookout-for-equipment/latest/ug/API_DeleteModel.html) API to remove the model trained in this tutorial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "published-newspaper",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting model getting-started-pump-5min-model...\n",
      "Model \"getting-started-pump-5min-model\" is deleted successfully.\n"
     ]
    }
   ],
   "source": [
    "for model in lookout.list_models_for_datasets(model_name_prefix=MODEL_NAME):\n",
    "    print(f'Deleting model {model}...')\n",
    "    \n",
    "    try:\n",
    "        lookout_client.delete_model(ModelName=MODEL_NAME)\n",
    "        print(f'Model \"{MODEL_NAME}\" is deleted successfully.')\n",
    "\n",
    "    except Exception as e:\n",
    "        error_code = e.response['Error']['Code']\n",
    "        # If the dataset is used by existing models and we asked a\n",
    "        # forced delete, we also delete the associated models before\n",
    "        # trying again the dataset deletion:\n",
    "        if (error_code == 'ConflictException'):\n",
    "            print(('Model is currently being used (a training might be in '\n",
    "                   'progress. Wait for the process to be completed and '\n",
    "                   'retry.'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceramic-exemption",
   "metadata": {},
   "source": [
    "### Deleting the dataset\n",
    "Using the [**DeleteDataset**](https://docs.aws.amazon.com/lookout-for-equipment/latest/ug/API_DeleteDataset.html) API to remove the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "subtle-guinea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset \"getting-started-pump-5min\" is deleted successfully.\n"
     ]
    }
   ],
   "source": [
    "# Let's try to delete this dataset:\n",
    "try:\n",
    "    lookout_client.delete_dataset(DatasetName=DATASET_NAME)\n",
    "    print(f'Dataset \"{DATASET_NAME}\" is deleted successfully.')\n",
    "\n",
    "except Exception as e:\n",
    "    error_code = e.response['Error']['Code']\n",
    "    if (error_code == 'ConflictException'):\n",
    "        print(('Dataset is used by at least a model, delete the '\n",
    "               'associated model(s) before deleting this dataset.'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acceptable-thesaurus",
   "metadata": {},
   "source": [
    "### Cleaning the S3 bucket\n",
    "Uncomment and run the following cell to clean the S3 bucket from the prefixes used throughout this tutorial for training data, label data and inference data. You can stop here if you would like to keep the data generated for further experimentation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "alternate-identification",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delete: s3://lookout-equipment-getting-started/getting_started/inference-data/input/centrifugal-pump_20210413195500.csv\n",
      "delete: s3://lookout-equipment-getting-started/getting_started/inference-data/input/centrifugal-pump_20210413200000.csv\n",
      "delete: s3://lookout-equipment-getting-started/getting_started/inference-data/input/centrifugal-pump_20210413194500.csv\n",
      "delete: s3://lookout-equipment-getting-started/getting_started/inference-data/input/centrifugal-pump_20210413195000.csv\n",
      "delete: s3://lookout-equipment-getting-started/getting_started/inference-data/input/centrifugal-pump_20210413203000.csv\n",
      "delete: s3://lookout-equipment-getting-started/getting_started/inference-data/input/centrifugal-pump_20210413201500.csv\n",
      "delete: s3://lookout-equipment-getting-started/getting_started/inference-data/output/2021-04-13T14:40:00Z/results.jsonl\n",
      "delete: s3://lookout-equipment-getting-started/getting_started/inference-data/output/2021-04-13T14:25:00Z/results.jsonl\n",
      "delete: s3://lookout-equipment-getting-started/getting_started/inference-data/output/2021-04-13T14:30:00Z/results.jsonl\n",
      "delete: s3://lookout-equipment-getting-started/getting_started/inference-data/input/centrifugal-pump_20210413200500.csv\n",
      "delete: s3://lookout-equipment-getting-started/getting_started/inference-data/input/centrifugal-pump_20210413201000.csv\n",
      "delete: s3://lookout-equipment-getting-started/getting_started/inference-data/output/2021-04-13T14:20:00Z/results.jsonl\n",
      "delete: s3://lookout-equipment-getting-started/getting_started/inference-data/output/2021-04-13T14:15:00Z/results.jsonl\n",
      "delete: s3://lookout-equipment-getting-started/getting_started/inference-data/output/2021-04-13T14:50:00Z/results.jsonl\n",
      "delete: s3://lookout-equipment-getting-started/getting_started/inference-data/output/2021-04-13T14:45:00Z/results.jsonl\n",
      "delete: s3://lookout-equipment-getting-started/getting_started/inference-data/output/.LOOKOUTEQUIPMENT_WRITE_ACCESS_CHECK_FILE_SAFE_TO_DELETE.TEMP\n",
      "delete: s3://lookout-equipment-getting-started/getting_started/inference-data/output/2021-04-13T14:55:00Z/results.jsonl\n",
      "delete: s3://lookout-equipment-getting-started/getting_started/inference-data/output/2021-04-13T15:00:00Z/results.jsonl\n",
      "delete: s3://lookout-equipment-getting-started/getting_started/inference-data/input/centrifugal-pump_20210413202000.csv\n",
      "delete: s3://lookout-equipment-getting-started/getting_started/inference-data/output/2021-04-13T14:35:00Z/results.jsonl\n",
      "delete: s3://lookout-equipment-getting-started/getting_started/inference-data/input/centrifugal-pump_20210413202500.csv\n",
      "delete: s3://lookout-equipment-getting-started/getting_started/training-data/centrifugal-pump/sensors.csv\n",
      "delete: s3://lookout-equipment-getting-started/getting_started/label-data/labels.csv\n"
     ]
    }
   ],
   "source": [
    "!aws s3 rm s3://$BUCKET/$PREFIX_INFERENCE --recursive\n",
    "!aws s3 rm s3://$BUCKET/$PREFIX_TRAINING --recursive\n",
    "!aws s3 rm s3://$BUCKET/$PREFIX_LABEL --recursive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "massive-hanging",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "first-reform",
   "metadata": {},
   "source": [
    "Use this notebook to cleanup all the ressources created while running this series of tutorials."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
